{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdd15af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ecdefae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2\n",
       "4                               i am feeling grouchy      3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv(r\"D:\\projects\\testing\\notebooks\\emotions\\training.csv\")\n",
    "valid_df=pd.read_csv(r\"D:\\projects\\testing\\notebooks\\emotions\\validation.csv\")\n",
    "test_df=pd.read_csv(r\"D:\\projects\\testing\\notebooks\\emotions\\test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d70566",
   "metadata": {},
   "source": [
    "sadness (0), joy (1), love (2), anger (3), fear (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "734e03a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c4672ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a62ea",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e3aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    \"\"\"Lemmatizes the input text.\"\"\"\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    words=text.split()\n",
    "    lemmatized_words=[]\n",
    "\n",
    "    for word in words:\n",
    "        word=lemmatizer.lemmatize(word)\n",
    "        lemmatized_words.append(word)\n",
    "    \n",
    "    result_text=' '.join(lemmatized_words)\n",
    "    return result_text\n",
    "\n",
    "def lower_case(text):\n",
    "    \"\"\"Converts the input text to lower case.\"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Removes stopwords from the input text.\"\"\"\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    words=text.split()\n",
    "    filtered_words=[]\n",
    "\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_words.append(word)\n",
    "    \n",
    "    result_text=' '.join(filtered_words)\n",
    "    return result_text\n",
    "\n",
    "def removing_numbers(text):\n",
    "    \"\"\"Removes numbers from input_text.\"\"\"\n",
    "    filtered_words=[]\n",
    "    words=text.split()\n",
    "\n",
    "    for word in words:\n",
    "        if not word.isdigit():\n",
    "            filtered_words.append(word)\n",
    "    result_text=' '.join(filtered_words)\n",
    "    return result_text\n",
    "\n",
    "def removing_urls(text):\n",
    "    \"\"\"Removes URLs from the text\"\"\"\n",
    "    url_pattern = r'https?://\\S+|www.\\S+'\n",
    "    result_text= re.sub(url_pattern, ' ', text)\n",
    "    return result_text\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    \"\"\"Removes punctuation form text\"\"\"\n",
    "    punctuation_pattern = f\"[{re.escape(string.punctuation)}]\"\n",
    "    result_text = re.sub(punctuation_pattern, ' ', text)\n",
    "    return result_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af2cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(df):\n",
    "    \"\"\"Normalize the text data.\"\"\"\n",
    "    try:\n",
    "        df['text'] = df['text'].apply(lower_case)\n",
    "        df['text'] = df['text'].apply(remove_stop_words)\n",
    "        df['text'] = df['text'].apply(removing_numbers)\n",
    "        df['text'] = df['text'].apply(removing_punctuations)\n",
    "        df['text'] = df['text'].apply(removing_urls)\n",
    "        df['text'] = df['text'].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error during text normalization: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "659db70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= normalize_text(train_df)\n",
    "valid_df= normalize_text(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "079a5441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling quite sad sorry ill snap soon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feel like still looking blank canvas blank pie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feel like faithful servant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feeling cranky blue</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>treat feeling festive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0           im feeling quite sad sorry ill snap soon      0\n",
       "1  feel like still looking blank canvas blank pie...      0\n",
       "2                         feel like faithful servant      2\n",
       "3                                feeling cranky blue      3\n",
       "4                              treat feeling festive      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddae7f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    5362\n",
       "0    4666\n",
       "3    2159\n",
       "4    1937\n",
       "2    1304\n",
       "5     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0673cffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    695\n",
       "0    581\n",
       "3    275\n",
       "4    224\n",
       "2    159\n",
       "5     66\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dafcd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as harshitneverdebugs\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as harshitneverdebugs\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"harshitneverdebugs/testing\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"harshitneverdebugs/testing\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository harshitneverdebugs/testing initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository harshitneverdebugs/testing initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1dd70d45af314efdafee614ecfdf3010', creation_time=1748203020719, experiment_id='0', last_update_time=1748203020719, lifecycle_stage='active', name='BiLSTM Baseline', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/harshitneverdebugs/testing.mlflow')\n",
    "dagshub.init(repo_owner='harshitneverdebugs', repo_name='testing', mlflow=True)\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"BiLSTM Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0633b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 21:15:44,331 - INFO - Starting MLflow BiLSTM run...\n",
      "2025-05-28 21:15:46,758 - INFO - Model compiled successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 55ms/step - accuracy: 0.3650 - loss: 1.5572 - val_accuracy: 0.7090 - val_loss: 0.8394\n",
      "Epoch 2/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.7998 - loss: 0.6196 - val_accuracy: 0.8900 - val_loss: 0.3327\n",
      "Epoch 3/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9333 - loss: 0.2096 - val_accuracy: 0.9060 - val_loss: 0.2857\n",
      "Epoch 4/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 44ms/step - accuracy: 0.9639 - loss: 0.1220 - val_accuracy: 0.9160 - val_loss: 0.2788\n",
      "Epoch 5/5\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9759 - loss: 0.0781 - val_accuracy: 0.9130 - val_loss: 0.2792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 21:16:48,059 - INFO - Model training completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 21:16:51,066 - WARNING - You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-05-28 21:16:54,732 - INFO - Accuracy: 0.7705\n",
      "2025-05-28 21:16:54,733 - INFO - Precision: 0.838632516107728\n",
      "2025-05-28 21:16:54,733 - INFO - Recall: 0.7705\n",
      "2025-05-28 21:16:54,733 - INFO - F1 Score: 0.7768934188124293\n",
      "2025-05-28 21:16:54,734 - INFO - Run completed in 70.01 seconds.\n",
      "2025/05/28 21:16:55 INFO mlflow.tracking._tracking_service.client: üèÉ View run stylish-shad-811 at: https://dagshub.com/harshitneverdebugs/testing.mlflow/#/experiments/0/runs/160bd6449ec747c7826b431f20e67d4c.\n",
      "2025/05/28 21:16:55 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: https://dagshub.com/harshitneverdebugs/testing.mlflow/#/experiments/0.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logging.info(\"Starting MLflow BiLSTM run...\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    start_time=time.time()\n",
    "    try:\n",
    "        MAX_FEATURES=10000\n",
    "        MAX_LEN=100\n",
    "        EMBEDDING_DIM=64\n",
    "\n",
    "        mlflow.log_param(\"model\", \"BiLSTM\")\n",
    "        mlflow.log_param(\"max_features\", MAX_FEATURES)\n",
    "        mlflow.log_param(\"max_len\", MAX_LEN)\n",
    "        mlflow.log_param(\"embedding_dim\", EMBEDDING_DIM)\n",
    "\n",
    "        tokenizer=Tokenizer(num_words=MAX_FEATURES, oov_token=\"<OOV>\")\n",
    "        tokenizer.fit_on_texts(train_df[\"text\"])\n",
    "\n",
    "        X_train=pad_sequences(tokenizer.texts_to_sequences(train_df[\"text\"]), maxlen=MAX_LEN)\n",
    "        X_valid=pad_sequences(tokenizer.texts_to_sequences(valid_df[\"text\"]), maxlen=MAX_LEN)\n",
    "        X_test=pad_sequences(tokenizer.texts_to_sequences(test_df[\"text\"]), maxlen=MAX_LEN)\n",
    "\n",
    "        y_train=train_df[\"label\"].values\n",
    "        y_valid=valid_df[\"label\"].values\n",
    "        y_test=test_df[\"label\"].values\n",
    "\n",
    "        num_classes = len(np.unique(train_df[\"label\"]))\n",
    "\n",
    "        y_train_cat=to_categorical(y_train, num_classes)\n",
    "        y_test_cat=to_categorical(y_test, num_classes)\n",
    "        y_valid_cat=to_categorical(y_valid, num_classes)\n",
    "\n",
    "        model=Sequential([\n",
    "            Embedding(input_dim=MAX_FEATURES, output_dim=EMBEDDING_DIM, input_length=MAX_LEN),\n",
    "            Bidirectional(LSTM(64, return_sequences=False)),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation=\"softmax\")\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "        logging.info(\"Model compiled successfully.\")\n",
    "\n",
    "        model.fit(X_train, y_train_cat, validation_data=[X_valid, y_valid_cat], epochs=5, batch_size=64)\n",
    "        logging.info(\"Model training completed.\")\n",
    "\n",
    "        y_pred_prob=model.predict(X_test)\n",
    "        y_pred=np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "        # Log metrics to MLflow\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        # Save model and log artifact\n",
    "        model.save(\"bilstm_model.h5\")\n",
    "        mlflow.log_artifact(\"bilstm_model.h5\")\n",
    "\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Run completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ad736c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361fbb71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
