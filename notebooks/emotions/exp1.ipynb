{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acdd15af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ecdefae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                            i didnt feel humiliated      0\n",
       "1  i can go from feeling so hopeless to so damned...      0\n",
       "2   im grabbing a minute to post i feel greedy wrong      3\n",
       "3  i am ever feeling nostalgic about the fireplac...      2\n",
       "4                               i am feeling grouchy      3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv(r\"D:\\projects\\testing\\notebooks\\emotions\\training.csv\")\n",
    "valid_df=pd.read_csv(r\"D:\\projects\\testing\\notebooks\\emotions\\validation.csv\")\n",
    "test_df=pd.read_csv(r\"D:\\projects\\testing\\notebooks\\emotions\\test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d70566",
   "metadata": {},
   "source": [
    "sadness (0), joy (1), love (2), anger (3), fear (4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734e03a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c4672ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a62ea",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e3aa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    \"\"\"Lemmatizes the input text.\"\"\"\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    words=text.split()\n",
    "    lemmatized_words=[]\n",
    "\n",
    "    for word in words:\n",
    "        word=lemmatizer.lemmatize(word)\n",
    "        lemmatized_words.append(word)\n",
    "    \n",
    "    result_text=' '.join(lemmatized_words)\n",
    "    return result_text\n",
    "\n",
    "def lower_case(text):\n",
    "    \"\"\"Converts the input text to lower case.\"\"\"\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Removes stopwords from the input text.\"\"\"\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    words=text.split()\n",
    "    filtered_words=[]\n",
    "\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            filtered_words.append(word)\n",
    "    \n",
    "    result_text=' '.join(filtered_words)\n",
    "    return result_text\n",
    "\n",
    "def removing_numbers(text):\n",
    "    \"\"\"Removes numbers from input_text.\"\"\"\n",
    "    filtered_words=[]\n",
    "    words=text.split()\n",
    "\n",
    "    for word in words:\n",
    "        if not word.isdigit():\n",
    "            filtered_words.append(word)\n",
    "    result_text=' '.join(filtered_words)\n",
    "    return result_text\n",
    "\n",
    "def removing_urls(text):\n",
    "    \"\"\"Removes URLs from the text\"\"\"\n",
    "    url_pattern = r'https?://\\S+|www.\\S+'\n",
    "    result_text= re.sub(url_pattern, ' ', text)\n",
    "    return result_text\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    \"\"\"Removes punctuation form text\"\"\"\n",
    "    punctuation_pattern = f\"[{re.escape(string.punctuation)}]\"\n",
    "    result_text = re.sub(punctuation_pattern, ' ', text)\n",
    "    return result_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6af2cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(df):\n",
    "    \"\"\"Normalize the text data.\"\"\"\n",
    "    try:\n",
    "        df['text'] = df['text'].apply(lower_case)\n",
    "        df['text'] = df['text'].apply(remove_stop_words)\n",
    "        df['text'] = df['text'].apply(removing_numbers)\n",
    "        df['text'] = df['text'].apply(removing_punctuations)\n",
    "        df['text'] = df['text'].apply(removing_urls)\n",
    "        df['text'] = df['text'].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error during text normalization: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c9f609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thaku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\thaku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\thaku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "659db70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df= normalize_text(train_df)\n",
    "valid_df= normalize_text(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "079a5441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling quite sad sorry ill snap soon</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>feel like still looking blank canvas blank pie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feel like faithful servant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feeling cranky blue</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>treat feeling festive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0           im feeling quite sad sorry ill snap soon      0\n",
       "1  feel like still looking blank canvas blank pie...      0\n",
       "2                         feel like faithful servant      2\n",
       "3                                feeling cranky blue      3\n",
       "4                              treat feeling festive      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddae7f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    5362\n",
       "0    4666\n",
       "3    2159\n",
       "4    1937\n",
       "2    1304\n",
       "5     572\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0673cffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    695\n",
       "0    581\n",
       "3    275\n",
       "4    224\n",
       "2    159\n",
       "5     66\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "929c53a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=100)\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_df['text'])\n",
    "y_train = train_df['label']\n",
    "\n",
    "X_valid = vectorizer.transform(valid_df['text'])\n",
    "y_valid = valid_df['label']\n",
    "\n",
    "X_test = vectorizer.transform(test_df['text'])\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5dafcd29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as harshitneverdebugs\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as harshitneverdebugs\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"harshitneverdebugs/testing\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"harshitneverdebugs/testing\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository harshitneverdebugs/testing initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository harshitneverdebugs/testing initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/26 01:27:00 INFO mlflow.tracking.fluent: Experiment with name 'BiLSTM Baseline' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1dd70d45af314efdafee614ecfdf3010', creation_time=1748203020719, experiment_id='0', last_update_time=1748203020719, lifecycle_stage='active', name='BiLSTM Baseline', tags={}>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/harshitneverdebugs/testing.mlflow')\n",
    "dagshub.init(repo_owner='harshitneverdebugs', repo_name='testing', mlflow=True)\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"BiLSTM Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0633b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
